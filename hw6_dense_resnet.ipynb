{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h31F7t2WnXQ"
      },
      "source": [
        "import numpy as np\n",
        "% tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpB0WAX9WyQH",
        "outputId": "a34a759d-f163-44ad-8875-b1199ff5227e"
      },
      "source": [
        "(train_images, train_labels),(test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YyoyUNmXkxV"
      },
      "source": [
        "print(\"The shape of the image set: \", train_images.shape)\n",
        "print(\"The shape of the label set: \", train_labels.shape)\n",
        "print(\"Print a label: \", train_labels[1])\n",
        "name_dict = {0: \"airplane\",1:\"automobile\", 2: \"bird\", 3: \"cat\", 4: \"deer\", 5: \"dog\", 6: \"frog\", 7: \"horse\", 8: \"ship\", 9: \"truck\"}\n",
        "fig, ax = plt.subplots(1,5)\n",
        "\n",
        "for count in range(5):\n",
        "  img = train_images[count]\n",
        "  label = int(train_labels[count])\n",
        "  ax[count].imshow(img)\n",
        "  ax[count].set_title(name_dict[label])\n",
        "  ax[count].axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwYQJCSlW_m2"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Perform necessary preprocessing steps to prepare the images and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFwaGb8CW-rZ"
      },
      "source": [
        "train_images = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "\n",
        "#normalizing image\n",
        "train_images = train_images.map(lambda img: img/255)\n",
        "\n",
        "train_labels = tf.data.Dataset.from_tensor_slices(train_labels.reshape((-1,)))\n",
        "train_labels = train_labels.map(lambda label: tf.one_hot(label,10))\n",
        "\n",
        "training_data = tf.data.Dataset.zip((train_images, train_labels))\n",
        "training_data = training_data.batch(64)\n",
        "training_data = training_data.shuffle(buffer_size = 64)\n",
        "training_data = training_data.prefetch(16)\n",
        "\n",
        "test_images = tf.data.Dataset.from_tensor_slices(test_images)\n",
        "\n",
        "#normalizing image\n",
        "test_images = test_images.map(lambda img: img/255)\n",
        "\n",
        "test_labels = tf.data.Dataset.from_tensor_slices(test_labels.reshape((-1,)))\n",
        "test_labels = test_labels.map(lambda label: tf.one_hot(label,10))\n",
        "\n",
        "test_data = tf.data.Dataset.zip((test_images, test_labels))\n",
        "test_data = test_data.batch(64)\n",
        "test_data = test_data.shuffle(buffer_size = 64)\n",
        "test_data = test_data.prefetch(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOfUhyNgZCxr"
      },
      "source": [
        "# Model\n",
        "## Model 1 ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX71RJ1TY-CR"
      },
      "source": [
        "class ResidualBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(ResidualBlock,self).__init__()\n",
        "\n",
        "    #Define the different layers we need\n",
        "    self.block = [tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, \n",
        "                                        kernel_regularizer = tf.keras.regularizers.l2(0.01), padding = 'same'),\n",
        "                  tf.keras.layers.BatchNormalization(),\n",
        "                  tf.keras.layers.activations.relu,\n",
        "\n",
        "                  tf.keras.layers.Conv2D(filters = 32, kernel_size = 3,\n",
        "                                        kernel_regularizer = tf.keras.regularizers.l2(0.01), padding = 'same'),\n",
        "                  tf.keras.layers.BatchNormalization(),\n",
        "                  tf.keras.layers.activations.relu\n",
        "    ]\n",
        "\n",
        "  def call(self, input_x):\n",
        "    x = input_x\n",
        "    for layer in self.block:\n",
        "      x = layer(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "civ4-8VggE5B"
      },
      "source": [
        "class ResNet(tf.keras.Model):\n",
        "  def __init__(self,numb_of_blocks):\n",
        "    super(ResNet, self).__init__()\n",
        "\n",
        "    self.blocks = []\n",
        "    self.blocks.append(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = tf.keras.activations.relu,\n",
        "                                        kernel_regularizer = tf.keras.regularizers.l2(0.01), padding = 'same'))\n",
        "    for _ in range(numb_of_blocks):\n",
        "      self.blocks.append(ResidualBlock())\n",
        "    \n",
        "    self.post_blocks = [\n",
        "                        tf.keras.layers.GlobalAveragePool(),\n",
        "                        tf.keras.layers.Dense(units = 10, activation= tf.keras.acitvations.softmax)\n",
        "    ]\n",
        "\n",
        "  def call(self, input_x):\n",
        "    x = input_x\n",
        "\n",
        "    for b in self.blocks:\n",
        "      x = b(x) + x\n",
        "    \n",
        "    for layer in self.post_blocks:\n",
        "      x = layer(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA8Ib27jhxB4"
      },
      "source": [
        "## Model 2 DenseNet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dj0qjuOhziz"
      },
      "source": [
        "class TransitionLayers(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(TransitionLayers,self).__init__()\n",
        "\n",
        "    #which layers should I use?\n",
        "    self.layers = [\n",
        "                   tf.keras.layers.Conv2d(filters = 64, kernel_size = 1),\n",
        "                   tf.keras.layers.MaxPool2D()\n",
        "    ]\n",
        "  \n",
        "  def call(self, input_x):\n",
        "    x = input_x\n",
        "\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "#class that describes one element of the block\n",
        "class Block(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(Block,self).__init__()\n",
        "\n",
        "    self.block = [\n",
        "             tf.keras.layers.Conv2d(filters = 32),\n",
        "             tf.keras.layers.BatchNormalization(),\n",
        "             tf.keras.layers.activations.relu\n",
        "    ]\n",
        "    \n",
        "    self.concatenate = tf.keras.layers.Concatenate()\n",
        "\n",
        "  def call(self, input_x):\n",
        "    x = input_x\n",
        "\n",
        "    for layer in self.block:\n",
        "      x = self.concatenate([layer(x),x])\n",
        "    \n",
        "    return x\n",
        "\n",
        "# class represents one denseblock consisting of multiple blocks\n",
        "class DenseBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, nr_blocks):\n",
        "    super(DenseBlock,self).__init__()\n",
        "\n",
        "    self.block = [Block() for _ in range(nr_blocks)]\n",
        "\n",
        "\n",
        "  def call(self, input_x):\n",
        "    x = input_x\n",
        "\n",
        "    for block in self.block:\n",
        "      x = block(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#the whole DenseNEt\n",
        "class DenseNet(tf.keras.Model):\n",
        "  def __init__(self, nr_blocks):\n",
        "    super(DenseNet,self).__init__()\n",
        "\n",
        "    self.blocks = []\n",
        "    self.blocks.append(tf.keras.layers.Conv2d(filters=125, activation = tf.keras.activations.relu, kernel_size = 3, padding = \"same\",\n",
        "                                              kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
        "\n",
        "    for i in range(nr_blocks):\n",
        "      self.blocks.append(DenseBlock())\n",
        "      \n",
        "      if (i < nr_blocks-1):\n",
        "        self.blocks.append(TransitionLayers())\n",
        "\n",
        "    self.blocks.append(tf.keras.layers.Flatten())\n",
        "    self.blocks.append(tf.keras.layers.Dense(units = 10, activation = tf.keras.activations.softmax))\n",
        "\n",
        "  def call(self, input_x):\n",
        "    x = input_x\n",
        "\n",
        "    for layer in self.block:\n",
        "      x = layer(x) \n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLaMYtxLKSiM"
      },
      "source": [
        "#Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa58KBmLKU_6"
      },
      "source": [
        "def train_step(model, input, target, loss_function, optimizer, training=True):\n",
        "  with tf.GradientTape() as tape:\n",
        "    prediction = model(input, training)\n",
        "    loss = loss_function(prediction,target) + tf.reduce_sum(model_losses)\n",
        "    accuracy = (np.argmax(axis =1, target) == np.argmax(axis=1, prediction)) / target.shape[0]\n",
        "    gradients = tape.gradient(loss,model.trainable_variables)\n",
        "  \n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss, accuracy\n",
        "\n",
        "\n",
        "def test(model, input_data, loss_function, training= False):\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "\n",
        "  for (image,label) in input_data:\n",
        "    predicition = model(image, training)\n",
        "    \n",
        "    #calculate the loss\n",
        "    loss = loss_function(prediction,label)\n",
        "\n",
        "    #calculate the accuracy by comparing the predicted label (of the model) to the ground truth (label)\n",
        "    accuracy = (np.argmax(prediction, axis=1) == np.argmax(target,axis=1))\n",
        "\n",
        "    losses.append(loss.numpy())\n",
        "    accuracies.appen(mean(accuracy))\n",
        "  \n",
        "  loss = np.mean(losses)\n",
        "  accuracy = np.mean(accuracies)\n",
        "  return loss, accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbmBiXePP34i"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "resnet = ResNet(numb_of_blocks = 3)\n",
        "densenet = DenseNet(nr_blocks = 3)\n",
        "\n",
        "epochs = 30\n",
        "learning_rate = 0.001\n",
        "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "running_Average_factor = 0.95\n",
        "\n",
        "steps = []\n",
        "#lists for both models\n",
        "resnet_losses = []\n",
        "resnet_accuracies = []\n",
        "\n",
        "densenet_losses = []\n",
        "densenet_accuracies = []\n",
        "\n",
        "#lists for testing both models\n",
        "res_test_losses = []\n",
        "res_test_accuracies = []\n",
        "\n",
        "dense_test_losses = []\n",
        "dense_test_accuracies = []\n",
        "\n",
        "\n",
        "#pretraining on training_data\n",
        "pre_loss, preaccur = test(resnet, training_data, loss_function)\n",
        "resnet_losses.append(pre_loss)\n",
        "resnet_accuracies.append(preaccur)\n",
        "\n",
        "pre_loss, preaccur = test(densenet, training_data, loss_function)\n",
        "densenet_losses.append(pre_loss)\n",
        "densenet_accuracies.append(preaccur)\n",
        "\n",
        "#pretraining test on test data:\n",
        "pre_loss, preaccur = test(resnet, test_data, loss_function)\n",
        "res_test_losses.append(pre_loss)\n",
        "res_test_accuracies.append(preaccur)\n",
        "\n",
        "pre_loss, preaccur = test(densenet, test_data, loss_function)\n",
        "dense_test_losses.append(pre_loss)\n",
        "dense_test_accuracies.append(preaccur)\n",
        "\n",
        "\n",
        "#actually start training\n",
        "for epoch in epochs:\n",
        "  steps.append(epoch)\n",
        "\n",
        "  train_dataset = train_dataset.shuffle(buffer_size=64)\n",
        "  test_dataset = test_dataset.shuffle(buffer_size=64)\n",
        "\n",
        "  running_accuracy_res = 0\n",
        "  running_accuracy_dense = 0\n",
        "  running_loss_res = 0\n",
        "  running_accuracy_dense = 0\n",
        "\n",
        "  # train the model on each input image\n",
        "  #compute the current loss and accuracy for both models\n",
        "  for(input,label) in train_dataset:\n",
        "    res_loss,res_accur = train(resnet, input, label, loss_function, optimizer)\n",
        "    dense_loss,dense_accur = train(densenet, input, label, loss_function, optimizer)\n",
        "\n",
        "    running_accuracy_dense = running_Average_factor * running_accuracy_dense + (1 - running_Average_factor) * dense_accur\n",
        "    running_accuracy_res = running_Average_factor * running_accuracy_res + (1 - running_Average_factor) * res_accur\n",
        "\n",
        "    running_loss_res = running_Average_factor * running_loss_res + (1 - running_Average_factor) * res_loss\n",
        "    running_loss_dense = running_Average_factor * running_loss_dense + (1 - running_Average_factor) * dense_loss\n",
        "  \n",
        "  # save the computed values (for the epoch)\n",
        "  resnet_accuracies.append(running_accuracy_res)\n",
        "  densenet_accuracies.append(running_accuracy_dense)\n",
        "\n",
        "  resnet_losses.append(running_loss_res)\n",
        "  densenet_losses.append(running_loss_dense)\n",
        "\n",
        "  #check how well the models do on the testing data\n",
        "  test_loss, test_accuracy = test(resnet, test_dataset, loss_function, False)\n",
        "  res_test_losses.append(test_loss)\n",
        "  res_accuracies.append(test_accuracy)\n",
        "\n",
        "  test_loss_d, test_accuracy_d = test(densenet, test_dataset, loss_function, False)\n",
        "  dense_test_losses.append(test_loss_d)\n",
        "  dense_test_accuracies.append(test_accuracy_d)\n",
        "\n",
        "\n",
        "  #print current performance data\n",
        "  print('RESNET: training_loss: ', running_loss_res.numpy(), 'training_accuracy: ', running_accuracy_res)\n",
        "  print('DENSENET: training_loss: ', running_loss_dense.numpy(), 'training_accuracy: ', running_accuracy_dense))\n",
        "  print('RESNET: test_loss: ', test_loss, 'test_accuracy: ', test_accuracy)\n",
        "  print('RESNET: test_loss: ', test_loss_d, 'test_accuracy: ', test_accuracy_d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ULX1qTYVQk9"
      },
      "source": [
        "\n",
        "#do the visualization\n",
        "#test loss and training loss\n",
        "plt.figure()\n",
        "line1, = plt.plot(resnet_losses)\n",
        "line2, = plt.plot(densenet_losses)\n",
        "line3, = plt.plot(res_test_losses)\n",
        "line4, = plt.plot(dense_test_losses)\n",
        "\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend((line1,line2, line3, line4),(\"ResNet training\", \"DenseNEt training\", \"ResNet test\", \"DenseNet test\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLsQHGSsVu8d"
      },
      "source": [
        "#do the visualization\n",
        "#test loss and training loss\n",
        "plt.figure()\n",
        "line1, = plt.plot(resnet_accuracies)\n",
        "line2, = plt.plot(densenet_accuracies)\n",
        "line3, = plt.plot(res_test_accuracies)\n",
        "line4, = plt.plot(dense_test_accuracies)\n",
        "\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend((line1,line2, line3, line4),(\"ResNet training\", \"DenseNEt training\", \"ResNet test\", \"DenseNet test\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}