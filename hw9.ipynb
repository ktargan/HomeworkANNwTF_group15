{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSR_FYdPvz7o"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to99YNHiyUl6"
      },
      "source": [
        "#generate the dataset\r\n",
        "BATCHSIZE = 32\r\n",
        "def generate_data(numb_samples, seq_length):\r\n",
        "  targets = [np.random.randint(low=0, high=10, size = 2) for i in range(numb_samples)]\r\n",
        "  sequences = [np.random.randint(low=0,high=10, size= seq_length) for i in range(numb_samples)]\r\n",
        "  \r\n",
        "  #Calculate the true results for the dataset\r\n",
        "  ground_truth = []\r\n",
        "  for target,seq in zip(targets,sequences):\r\n",
        "    ground_truth.append(calculate_target(target, seq))\r\n",
        "\r\n",
        "  sequences = tf.data.Dataset.from_tensor_slices(sequences)\r\n",
        "  sequences = sequences.map(lambda seq: tf.one_hot(seq,10))\r\n",
        "  targets = tf.data.Dataset.from_tensor_slices(targets)\r\n",
        "  targets = targets.map(lambda t: tf.one_hot(t,10))\r\n",
        "\r\n",
        "  ground_truth = tf.data.Dataset.from_tensor_slices(ground_truth)\r\n",
        "  #Combine everything into a dataset\r\n",
        "  dataset = tf.data.Dataset.zip((sequences, targets, ground_truth))\r\n",
        "\r\n",
        "  dataset = dataset.batch(BATCHSIZE)\r\n",
        "  dataset = dataset.shuffle(BATCHSIZE)\r\n",
        "  dataset = dataset.prefetch(8)\r\n",
        "\r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz3A128tcCCo"
      },
      "source": [
        "'''Function to calculate which of the two queried target_options appears more often in the sequence'''\r\n",
        "def calculate_target(target_options, sequence):\r\n",
        "  \r\n",
        "  first_target = np.sum(sequence == target_options[0])\r\n",
        "  second_target = np.sum(sequence == target_options[1])\r\n",
        "\r\n",
        "  #if the first target number appears more often or equally often as the second we will return 0\r\n",
        "  larger_sum = 0\r\n",
        "  if first_target < second_target:\r\n",
        "    larger_sum = 1\r\n",
        "\r\n",
        "  return larger_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBFqJNEL35Do",
        "outputId": "7654c10b-7ffa-42af-f417-395183239185"
      },
      "source": [
        "gen = generate_data(1,3)\r\n",
        "for elem in gen.take(1):\r\n",
        "  print(elem)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(1, 3, 10), dtype=float32, numpy=\n",
            "array([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]], dtype=float32)>, <tf.Tensor: shape=(1, 2, 10), dtype=float32, numpy=\n",
            "array([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPtqvt-ePnTm"
      },
      "source": [
        "#LSTM Cell\r\n",
        "class LSTMCell(tf.keras.layers.Layer):\r\n",
        "  def __init__(self, units):\r\n",
        "    super(LSTMCell, self).__init__()\r\n",
        "\r\n",
        "    #gates as dense layers with respective activation function\r\n",
        "    self.forget_gate = tf.keras.layers.Dense(units, activation = tf.keras.activations.sigmoid, bias_initializer='ones')\r\n",
        "    self.input_gate = tf.keras.layers.Dense(units, activation = tf.keras.activations.sigmoid)\r\n",
        "    self.output_gate = tf.keras.layers.Dense(units, activation = tf.keras.activations.sigmoid)\r\n",
        "    \r\n",
        "    #cell state candidates with tanh\r\n",
        "    self.candidates = tf.keras.layers.Dense(units, activation = tf.keras.activations.tanh)\r\n",
        "\r\n",
        "  def call(self, sequence, hidden_state, cell_state):\r\n",
        "    #concatenate input and hidden state\r\n",
        "    concat_input = tf.concat((tf.cast(hidden_state, dtype=tf.int32), tf.cast(sequence, dtype=tf.int32)), axis = 1)\r\n",
        "\r\n",
        "    #forget part of cell state\r\n",
        "    cell_state = cell_state * self.forget_gate(concat_input)\r\n",
        "\r\n",
        "    #compute update for cell state\r\n",
        "    update = self.input_gate(concat_input) * self.candidates(concat_input)\r\n",
        "    #use input gate and candidates to update cell state\r\n",
        "    cell_state = cell_state + update\r\n",
        "\r\n",
        "    #compute new hidden state\r\n",
        "    hidden_state = self.output_gate(concat_input) * tf.keras.activations.tanh(cell_state)\r\n",
        "\r\n",
        "    #ouput the hidden state\r\n",
        "    return hidden_state, cell_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bXqIRSHP-et"
      },
      "source": [
        "class LSTM(tf.keras.Model):\r\n",
        "  def __init__(self):\r\n",
        "    super(LSTM, self).__init__()\r\n",
        "    self.cell = LSTMCell(units=2)\r\n",
        "\r\n",
        "    #initialize cell_state\r\n",
        "    self.cell_state = tf.zeros(shape=(BATCHSIZE, 2))\r\n",
        "    self.hidden_state = tf.zeros(shape =(BATCHSIZE, 2))\r\n",
        "    self.flatten = tf.keras.layers.Flatten()\r\n",
        "    #output which of the target numbers is more likely\r\n",
        "    self.read_out = tf.keras.layers.Dense(units=1, activation=tf.keras.activations.sigmoid)\r\n",
        "  \r\n",
        "  def call(self, data,query):\r\n",
        "    #sequence and query concatenation\r\n",
        "    for i in range(len(data[1])):\r\n",
        "      #concatenate each sequence element with the respective queries\r\n",
        "      x = tf.concat((data[:,i,:],tf.reshape(query,[32,20])),axis = 1)\r\n",
        "\r\n",
        "      if(i == 0):\r\n",
        "        current_hidden_state, current_cell_state = self.cell(x, self.hidden_state, self.cell_state)\r\n",
        "      current_hidden_state, current_cell_state = self.cell(x, current_hidden_state, current_cell_state)\r\n",
        "\r\n",
        "    x = self.flatten(current_hidden_state)\r\n",
        "    x = self.read_out(x)\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unt9CmIoUUXX"
      },
      "source": [
        "def train_step(model, data, query, target, loss_function, optimizer):\r\n",
        "  \r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    prediction = model(data,query)\r\n",
        "\r\n",
        "    #calculate the loss \r\n",
        "    loss = loss_function(tf.squeeze(prediction), tf.cast(target, dtype=tf.float32)) # solved TypeError: Cannot convert 1e-07 to EagerTensor of dtype int32\r\n",
        "    #calculate the accuracy by moving along the vector of targets (per input)\r\n",
        "    accuracy = np.sum(np.abs((tf.cast(target, dtype=tf.float32)-tf.squeeze(prediction)))<0.5)/target.shape[0]\r\n",
        "    #calculate the gradients for the weights with respect to the loss\r\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "\r\n",
        "  #update the weights\r\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "\r\n",
        "  return loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAuSmwEria-9"
      },
      "source": [
        "import time\r\n",
        "def timing(start):\r\n",
        "    now = time.time()\r\n",
        "    time_per_training_step = now - start\r\n",
        "    # compute duration of an epoch\r\n",
        "    return round(time_per_training_step, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znqyJuXwc2R9",
        "outputId": "a851efc5-90de-45f3-c467-1eec92e75b55"
      },
      "source": [
        "#train\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "#create data\r\n",
        "train_data = generate_data(60000,30)\r\n",
        "\r\n",
        "#model\r\n",
        "model = LSTM()\r\n",
        "\r\n",
        "#Define hyperparameters\r\n",
        "#How many training epochs do we perform\r\n",
        "epochs = 5\r\n",
        "#define the learning rate which influences the magnitude with which we update the models parameters\r\n",
        "learning_rate = 0.001\r\n",
        "loss_function = tf.keras.losses.MSE\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\r\n",
        "\r\n",
        "running_average_factor = 0.95\r\n",
        "\r\n",
        "steps = []\r\n",
        "train_losses = []\r\n",
        "train_accuracy = []\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "  print(epoch, \". epoch --------------------------------------------------------------------------------\")\r\n",
        "  steps.append(epoch)\r\n",
        "\r\n",
        "\r\n",
        "  start = time.time()\r\n",
        "  original_loss = 0\r\n",
        "  original_acc = 0\r\n",
        "  for data,query,target in train_data:\r\n",
        "    train_loss,train_acc = train_step(model, data, query, target, loss_function, optimizer)\r\n",
        "\r\n",
        "    original_loss = running_average_factor * original_loss + (1-running_average_factor) * train_loss\r\n",
        "    original_acc = running_average_factor * original_acc + (1-running_average_factor) * train_acc\r\n",
        "\r\n",
        "  train_losses.append(original_loss)\r\n",
        "  train_accuracy.append(original_acc)\r\n",
        "\r\n",
        "\r\n",
        "  print(f\"the training step and test evaluation took {timing(start)} seconds\")\r\n",
        "  #some sort of plotting\r\n",
        "  print(\"train_loss\", original_loss.numpy())\r\n",
        "  print(\"train accuracy\", original_acc)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 . epoch --------------------------------------------------------------------------------\n",
            "the training step and test evaluation took 185.41 seconds\n",
            "train_loss 0.23191383\n",
            "train accuracy 0.6283969569415837\n",
            "1 . epoch --------------------------------------------------------------------------------\n",
            "the training step and test evaluation took 182.8 seconds\n",
            "train_loss 0.22754252\n",
            "train accuracy 0.6354780465329194\n",
            "2 . epoch --------------------------------------------------------------------------------\n",
            "the training step and test evaluation took 180.12 seconds\n",
            "train_loss 0.22906043\n",
            "train accuracy 0.6297530676654249\n",
            "3 . epoch --------------------------------------------------------------------------------\n",
            "the training step and test evaluation took 180.17 seconds\n",
            "train_loss 0.2149879\n",
            "train accuracy 0.6617467184107219\n",
            "4 . epoch --------------------------------------------------------------------------------\n",
            "the training step and test evaluation took 179.12 seconds\n",
            "train_loss 0.21420978\n",
            "train accuracy 0.6690564069646223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBVfSqw9dDDm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q63t-jDYTqY8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "dc01623e-fab1-45c9-948a-9838211f65d3"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "#do the visualization\r\n",
        "#test loss and training loss\r\n",
        "plt.figure()\r\n",
        "line1, = plt.plot(train_losses)\r\n",
        "line2, = plt.plot(train_accuracy)\r\n",
        "plt.xlabel(\"Training steps\")\r\n",
        "plt.legend((line1,line2),(\"loss\",\"accuracy\"))\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2hEGXsH0Nmg"
      },
      "source": [
        "We assume that it is slowly going to increase with every additional epoch (as seen in this trend), due to timing constraints we were not able to train it for a longer time.\r\n",
        "\r\n",
        "We are pretty sure about our implementation but there might be a bug somewhere in the code anyway. After hours of debugging we feel that we have implemented the general idea and task and have thus completed it to the best of our abilities. "
      ]
    }
  ]
}